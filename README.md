# DTU 02501 — Advanced Deep Learning in Computer Vision

> **Semester:** Spring 2025 | **ECTS:** 10 | **Institution:** Technical University of Denmark (DTU)

This repository contains the complete lecture notes and supplementary material for **DTU 02501 – Advanced Deep Learning in Computer Vision**. The course explores state‑of‑the‑art deep‑learning techniques for visual understanding and generation, spanning transformers, diffusion models, self‑supervised & multimodal learning, explainability, and fairness.

---

## Table of Contents

1. [Course Overview](#course-overview)
2. [Lectures](#lectures)
3. [Hands‑on Exercises](#hands-on-exercises)
4. [Projects & Extras](#projects--extras)
5. [Glossary](#glossary)
6. [Contributing](#contributing)
7. [License](#license)

---

## Course Overview

|                       |                                                                                                                                                                                                                                                 |
| --------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Prerequisites**     | ‣ Python & PyTorch basics  <br>‣ Linear algebra & probability  <br>‣ Intro‑level machine learning                                                                                                                                               |
| **Learning Outcomes** | 1. Explain & implement transformer‑based CV models.<br>2. Train and evaluate diffusion‑based generative models.<br>3. Apply self‑supervised & multimodal representation learning.<br>4. Assess model fairness, explainability & ethical impact. |

---

## Lectures

|  #  | Topic                                  |
| --- | -------------------------------------- |
| 1   | **Transformers, Attention & Encoders** |
| 2   | **Visual Transformers**                |
| 3   | **Transformer Decoders, LLMs & GPTs**  |
| 4   | **Diffusion Models – Foundations**     |
| 5   | **Diffusion Guidance**                 |
| 6   | **SOTA Text‑to‑Image Generation**      |
| 7   | **Self‑Supervised Learning**           |
| 8   | **Multi‑Modal Learning**               |
| 9   | **Explainable AI**                     |
| 10  | **Fairness in Computer Vision**        |

> *Slides & detailed markdown summaries for each lecture are located in the `lectures/` directory.*

---

## Hands‑on Exercises

|  Exercise  | Focus                                              |
| ---------- | -------------------------------------------------- |
|  1         | Fundamentals & code warm‑up                        |
|  2         | Convolutional baselines vs Vision Transformers     |
|  3         | **AndersenGPT** – Large‑language‑model fine‑tuning |
|  4         | Guided Diffusion Models                            |
|  5         | Textual Inversion for concept‑driven generation    |

Each exercise includes starter notebooks, datasets and expected deliverables in `exercises/`.

---

## Projects & Extras

* **Stable Diffusion vs Stable Diffusion XL** — empirical comparison notes
* **Project in‑depth knowledge** — problem statement, data, models, training details, results

---

## Glossary

A concise glossary of key terms across transformers, generative models, explainability and fairness is provided in `glossary.md`.

---

## Contributing

Pull requests are welcome! Please open an issue first to discuss major changes.

---

## License

This repository is distributed under the MIT License — see `LICENSE` for details.
